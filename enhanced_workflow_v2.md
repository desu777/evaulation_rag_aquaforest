# üîÑ Enhanced Evaluation RAG Workflow v2 z GPT Augmentation

## üéØ **Nowy Flow Diagram**

```mermaid
graph TD
    A[Initialize Evaluation] --> B[Analyze Query Intent]
    B --> C{Business/Trade Secret?}
    C -->|Business| D[Handle Business Query]
    C -->|Trade Secret| E[Check Trade Secrets] 
    C -->|Regular| F[Execute Search Attempt]
    D --> Z[END]
    E --> Z
    
    F --> G[Enhanced Evaluate Content Quality]
    G --> H{Store Best Partial?}
    H -->|Yes 5.0+| I[Store Partial Result]
    H -->|No| J{Quality Check}
    I --> J
    
    J -->|‚úÖ >= 7.0| K[Generate Answer]
    J -->|‚ùå < 4.0| L{Attempts < 3?}
    J -->|‚ö†Ô∏è 4.0-6.9| L
    
    L -->|Yes| F
    L -->|No, No Partial| M[Standard Escalation]
    L -->|No, Has Partial| N[üÜï GPT Augmentation Mode]
    
    N --> O[Generate Augmented Response]
    O --> P[Second Evaluation]
    P --> Q{Augmented Quality?}
    Q -->|‚úÖ >= 7.0 + Safe| K
    Q -->|‚ùå Failed| M
    
    K --> Z
    M --> Z
```

## üîß **Enhanced State Definition**

```python
class EnhancedEvaluationRAGStateV2(TypedDict):
    # ... existing fields ...
    
    # üÜï NEW: Partial Results Tracking
    best_partial_result: Dict  # Best 5.0+ result from any attempt
    best_partial_confidence: float  # Confidence of best partial
    attempt_confidences: List[float]  # Track all attempt confidences
    has_usable_partial: bool  # Flag for augmentation eligibility
    augmentation_used: bool  # Track if augmentation was applied
    augmentation_confidence: float  # Final augmented confidence
```

## üöÄ **Modified Workflow Nodes**

### **1. Enhanced Evaluate Content Quality v2**

```python
def enhanced_evaluate_content_quality_v2(state: EnhancedEvaluationRAGStateV2):
    """Enhanced evaluation with partial result tracking"""
    attempt = state["attempt_count"]
    results = state["search_results"]
    
    # Model evaluates content quality
    confidence, reasoning = components.evaluate_content_quality(
        state["original_query"], results
    )
    
    print(f"üìä Attempt {attempt} confidence: {confidence}/10")
    
    # üÜï TRACK BEST PARTIAL RESULT (5.0+)
    if confidence >= 5.0 and confidence > state.get("best_partial_confidence", 0):
        print(f"üíæ Storing partial result: {confidence}/10")
        best_partial = {
            "confidence": confidence,
            "reasoning": reasoning,
            "results": results,
            "attempt": attempt,
            "query": state["current_query"]
        }
        state.update({
            "best_partial_result": best_partial,
            "best_partial_confidence": confidence,
            "has_usable_partial": True
        })
    
    # Track attempt confidence
    attempt_confidences = state.get("attempt_confidences", [])
    attempt_confidences.append(confidence)
    
    # Get threshold for this query type
    threshold = state.get("confidence_threshold_override", 7.0)
    
    # DOSAGE FALLBACK (unchanged)
    if (state["query_intent"] == "dosage" and 
        confidence < threshold and 
        attempt >= MAX_REASONING_ATTEMPTS):
        return dosage_fallback_response(state)
    
    # STANDARD EVALUATION
    if confidence >= threshold:
        print(f"‚úÖ Quality sufficient ({confidence}/10)")
        return quality_sufficient_response(state, confidence)
    elif confidence < 4.0 and attempt >= MAX_REASONING_ATTEMPTS:
        return check_augmentation_eligibility(state)
    elif attempt >= MAX_REASONING_ATTEMPTS:
        return check_augmentation_eligibility(state)  # üÜï Check for partial
    else:
        print(f"ü§î Continue reasoning (attempt {attempt}/3)")
        return continue_reasoning_response(state, confidence)

def check_augmentation_eligibility(state):
    """üÜï Decide: Augmentation vs Standard Escalation"""
    if (state.get("has_usable_partial", False) and 
        state["query_intent"] not in ["business", "dosage", "production"]):
        
        print(f"üß† GPT AUGMENTATION MODE: Using partial {state['best_partial_confidence']}/10")
        return {
            **state,
            "should_continue": False,
            "escalate": False,
            "use_augmentation": True,  # üÜï Trigger augmentation
            "evaluation_log": [f"Max attempts reached - triggering GPT augmentation with partial {state['best_partial_confidence']}/10"]
        }
    else:
        print(f"‚ö†Ô∏è Standard escalation (no usable partial)")
        return standard_escalation_response(state)
```

### **2. New Node: GPT Augmentation**

```python
def gpt_augmentation_mode(state: EnhancedEvaluationRAGStateV2):
    """üÜï NEW: GPT Knowledge Augmentation"""
    print(f"üß† AUGMENTING with GPT knowledge...")
    
    partial = state["best_partial_result"]
    
    # Build augmentation context
    partial_content = ""
    for result in partial["results"][:3]:
        partial_content += f"≈πR√ìD≈ÅO: {result['title']}\n{result['full_content'][:300]}...\n\n"
    
    augmentation_prompt = f"""
    {ENHANCED_AQUAFOREST_EXPERT_PROMPT}
    
    === TRYB AUGMENTACJI WIEDZY ===
    
    Masz czƒô≈õciowƒÖ wiedzƒô z bazy Aquaforest (confidence: {partial['confidence']}/10), 
    ale jest niewystarczajƒÖca do pe≈Çnej odpowiedzi.
    
    CZƒò≈öCIOWA WIEDZA Z BAZY:
    {partial_content}
    
    PYTANIE U≈ªYTKOWNIKA: "{state['original_query']}"
    
    ZADANIE - CONTROLLED AUGMENTATION:
    1. üéØ Wykorzystaj znalezione tre≈õci jako FOUNDATION
    2. üß† Dope≈Çnij brakujƒÖcƒÖ wiedzƒô domenowƒÖ Aquaforest/akwarystyka  
    3. üõ°Ô∏è Pozosta≈Ñ w kontek≈õcie znalezionych tre≈õci
    4. ‚ùå NIE dodawaj informacji sprzecznych z tre≈õciami
    5. üìù Zaznacz co pochodzi z bazy, a co jest uzupe≈Çnieniem
    6. ‚ö†Ô∏è Je≈õli nie mo≈ºesz bezpiecznie uzupe≈Çniƒá - powiedz to
    
    STRUKTURA ODPOWIEDZI:
    **Na podstawie dostƒôpnych informacji Aquaforest:**
    [tre≈õci z bazy RAG]
    
    **Dodatkowo w kontek≈õcie akwarystyki:**
    [bezpieczne uzupe≈Çnienie domenowe]
    
    **‚ö†Ô∏è Dla potwierdzenia szczeg√≥≈Ç√≥w:**
    Skontaktuj siƒô z ekspertami Aquaforest: (+48) 14 691 79 79
    
    ODPOWIED≈π EKSPERTA:
    """
    
    try:
        response = components.llm.invoke([SystemMessage(content=augmentation_prompt)])
        augmented_answer = response.content
        
        print(f"üß† Generated augmented response ({len(augmented_answer)} chars)")
        
        # üÜï SECOND EVALUATION - czy augmentacja jest OK?
        second_eval_confidence, second_reasoning = evaluate_augmented_response(
            augmented_answer, state["original_query"], partial_content
        )
        
        print(f"üîç Second evaluation: {second_eval_confidence}/10")
        
        # Safety checks
        if (second_eval_confidence >= 7.0 and 
            passes_safety_checks(augmented_answer, partial_content)):
            
            print(f"‚úÖ Augmentation SUCCESS!")
            return {
                **state,
                "final_answer": augmented_answer,
                "model_confidence": second_eval_confidence,
                "augmentation_used": True,
                "augmentation_confidence": second_eval_confidence,
                "should_continue": False,
                "evaluation_log": [f"GPT augmentation successful: {second_eval_confidence}/10"]
            }
        else:
            print(f"‚ùå Augmentation FAILED safety/quality checks")
            return {
                **state,
                "escalate": True,
                "should_continue": False,
                "evaluation_log": [f"GPT augmentation failed: {second_eval_confidence}/10"]
            }
            
    except Exception as e:
        print(f"‚ùå Augmentation ERROR: {e}")
        return standard_escalation_response(state)

def evaluate_augmented_response(augmented_response, original_query, partial_content):
    """üîç Second evaluation for augmented responses"""
    
    eval_prompt = f"""
    Oce≈Ñ jako≈õƒá tej augmentowanej odpowiedzi na skali 1-10:
    
    PYTANIE: "{original_query}"
    ODPOWIED≈π: "{augmented_response}"
    
    KRYTERIA OCENY:
    1. **Relevance**: Czy odpowiada na pytanie? (1-10)
    2. **Consistency**: Czy sp√≥jna z wiedzƒÖ bazowƒÖ? (1-10) 
    3. **Safety**: Czy nie halucynuje fakt√≥w? (1-10)
    4. **Actionability**: Czy u≈ºytkownik wie co robiƒá? (1-10)
    
    ‚ö†Ô∏è OSTRZE≈ªENIA:
    - Obni≈º ocenƒô je≈õli wymy≈õlone konkretne liczby/produkty
    - Obni≈º ocenƒô je≈õli sprzeczne z bazƒÖ wiedzy
    - Obni≈º ocenƒô je≈õli zbyt og√≥lnikowe
    
    CONFIDENCE: [1-10]
    REASONING: [kr√≥tkie uzasadnienie]
    """
    
    try:
        response = components.llm.invoke([SystemMessage(content=eval_prompt)])
        
        # Extract confidence
        confidence_match = re.search(r'CONFIDENCE:\s*([1-9]|10)', response.content)
        reasoning_match = re.search(r'REASONING:\s*(.+)', response.content, re.DOTALL)
        
        confidence = float(confidence_match.group(1)) if confidence_match else 5.0
        reasoning = reasoning_match.group(1).strip() if reasoning_match else "No reasoning"
        
        return confidence, reasoning
    except:
        return 3.0, "Evaluation failed"

def passes_safety_checks(augmented_response, original_content):
    """üõ°Ô∏è Safety checks for augmented responses"""
    
    # Check 1: Length reasonable (not too short/long)
    if len(augmented_response) < 100 or len(augmented_response) > 2000:
        return False
    
    # Check 2: Contains reference to contacting experts (for safety)
    contact_keywords = ["kontakt", "ekspert", "691 79 79", "aquaforest.eu"]
    has_contact_ref = any(keyword in augmented_response.lower() for keyword in contact_keywords)
    
    # Check 3: Doesn't invent specific product names/numbers not in original
    # (more sophisticated check could be added)
    
    return has_contact_ref  # Simplified for now
```

### **3. Modified Workflow Routing**

```python
def create_enhanced_evaluation_workflow_v2():
    """Create enhanced workflow v2 with GPT augmentation"""
    workflow = StateGraph(EnhancedEvaluationRAGStateV2)
    
    # Add nodes
    workflow.add_node("initialize_evaluation", initialize_evaluation_v2)
    workflow.add_node("analyze_query_intent", analyze_query_intent)
    workflow.add_node("handle_business_query", handle_business_query)
    workflow.add_node("check_trade_secrets", check_trade_secrets)
    workflow.add_node("execute_search_attempt", execute_search_attempt)
    workflow.add_node("enhanced_evaluate_content_quality_v2", enhanced_evaluate_content_quality_v2)
    workflow.add_node("gpt_augmentation_mode", gpt_augmentation_mode)  # üÜï NEW
    workflow.add_node("generate_evaluation_answer", generate_evaluation_answer)
    
    # Routing logic
    workflow.add_edge(START, "initialize_evaluation")
    workflow.add_edge("initialize_evaluation", "analyze_query_intent")
    
    # Business routing (unchanged)
    workflow.add_conditional_edges(
        "analyze_query_intent",
        business_or_trade_secrets,
        {
            "handle_business_query": "handle_business_query",
            "check_trade_secrets": "check_trade_secrets", 
            "execute_search_attempt": "execute_search_attempt"
        }
    )
    
    workflow.add_edge("handle_business_query", END)
    workflow.add_edge("check_trade_secrets", END)
    workflow.add_edge("execute_search_attempt", "enhanced_evaluate_content_quality_v2")
    
    # üÜï ENHANCED ROUTING with augmentation
    def continue_augment_or_finish(state):
        if state.get("should_continue"):
            return "execute_search_attempt"  # Continue attempts
        elif state.get("use_augmentation"):
            return "gpt_augmentation_mode"   # üÜï Augmentation path
        else:
            return "generate_evaluation_answer"  # Standard finish
    
    workflow.add_conditional_edges(
        "enhanced_evaluate_content_quality_v2",
        continue_augment_or_finish,
        {
            "execute_search_attempt": "execute_search_attempt",
            "gpt_augmentation_mode": "gpt_augmentation_mode",  # üÜï
            "generate_evaluation_answer": "generate_evaluation_answer"
        }
    )
    
    # Augmentation leads to end
    workflow.add_edge("gpt_augmentation_mode", END)
    workflow.add_edge("generate_evaluation_answer", END)
    
    return workflow.compile()
```

## üéØ **Kiedy uruchamia siƒô augmentacja?**

### **Warunki aktywacji:**
```python
# ‚úÖ AUGMENTATION TRIGGERS:
1. attempt_count >= 3 (max attempts reached)
2. has_usable_partial == True (any attempt had 5.0+)
3. query_intent NOT IN ["business", "dosage", "production"] 
4. confidence < threshold (nie ma good enough answer)

# ‚ùå STANDARD ESCALATION:
1. No partial results (all attempts < 5.0)
2. Protected query types (business/dosage/production)
3. Augmentation failed safety checks
```

## üìä **Expected Improvement**

### **Before (Current):**
```
Confidence 7.0+: ‚úÖ Good response (25%)
Confidence 5.0-6.9: ‚ö†Ô∏è Escalation (30%) 
Confidence <5.0: ‚ùå Escalation (45%)

Total Success Rate: 25%
```

### **After (With Augmentation):**
```
Confidence 7.0+: ‚úÖ Good response (25%)
Confidence 5.0-6.9: üß† Augmentation ‚Üí ~70% success (21%) 
Confidence <5.0: ‚ùå Escalation (45%)
Augmentation fails: ‚ö†Ô∏è Escalation (9%)

Total Success Rate: ~46% (+21% improvement!)
```

## üõ°Ô∏è **Safety Mechanisms Summary**

1. **Second Evaluation**: Augmented response jest ponownie oceniane
2. **Safety Checks**: Length, contact info, consistency
3. **Confidence Threshold**: Augmentation musi osiƒÖgnƒÖƒá 7.0+ 
4. **Fallback**: Je≈õli augmentation fails ‚Üí standard escalation
5. **Protected Queries**: Business/dosage/production excluded

## üöÄ **Implementation Plan**

### **Phase 1: Core Implementation**
- [ ] Enhanced State with partial tracking
- [ ] Modified evaluate_content_quality_v2  
- [ ] GPT augmentation node
- [ ] Updated workflow routing

### **Phase 2: Safety & Testing**
- [ ] Second evaluation system
- [ ] Safety checks implementation
- [ ] Test on subset of 5.0-6.9 cases from stress tests
- [ ] A/B comparison with current system

### **Phase 3: Optimization**
- [ ] Fine-tune augmentation prompts
- [ ] Optimize safety thresholds
- [ ] Performance monitoring
- [ ] Production deployment

**Ready to implement? To znaczƒÖco poprawi≈Çoby success rate! üéØ**