# workflow_nodes.py v3 - Enhanced Workflow Nodes with Dynamic Optimization
import re
from typing import List
from datetime import datetime
from langchain_core.messages import SystemMessage
from state import EnhancedEvaluationRAGStateV2
from components import EvaluationRAGComponents
from config import ENHANCED_AQUAFOREST_EXPERT_PROMPT, MAX_REASONING_ATTEMPTS

# Initialize enhanced components with dynamic optimization
components = EvaluationRAGComponents()

def initialize_evaluation_v2(state: EnhancedEvaluationRAGStateV2) -> EnhancedEvaluationRAGStateV2:
    """Node 1: Initialize enhanced evaluation with partial tracking"""
    print(f"üß† ENHANCED EVALUATION RAG v2: {state['original_query']}")
    print("üéØ Model-based quality assessment + GPT Augmentation + Dynamic Optimization")
    
    return {
        **state,
        "current_query": state['original_query'],
        "attempt_count": 0,
        "attempt_history": [],
        "all_results": [],
        "evaluation_log": [f"Starting evaluation for: '{state['original_query']}'"],
        "should_continue": True,
        "escalate": False,
        "query_intent": "general",
        "business_type": "none",
        "requires_trade_secret_filter": False,
        "confidence_threshold_override": 7.0,
        "company_context_added": False,
        # üÜï NEW: Initialize augmentation tracking
        "best_partial_result": None,
        "best_partial_confidence": 0.0,
        "attempt_confidences": [],
        "has_usable_partial": False,
        "use_augmentation": False,
        "augmentation_used": False,
        "augmentation_confidence": 0.0,
        "augmentation_reasoning": ""
    }

def enhanced_evaluate_content_quality_v2(state: EnhancedEvaluationRAGStateV2) -> EnhancedEvaluationRAGStateV2:
    """Node 3: Enhanced evaluation with partial result tracking and augmentation logic"""
    attempt = state["attempt_count"]
    results = state["search_results"]
    
    print(f"ü§ñ Model evaluating content quality (attempt {attempt})...")
    
    # Model evaluates content (ignoring Pinecone scores)
    confidence, reasoning = components.evaluate_content_quality(
        state["original_query"], 
        results
    )
    
    print(f"üìä Attempt {attempt} confidence: {confidence}/10")
    print(f"üí≠ Reasoning: {reasoning[:100]}...")
    
    # üÜï TRACK BEST PARTIAL RESULT (5.0+)
    current_best = state.get("best_partial_confidence", 0.0)
    if confidence >= 5.0 and confidence > current_best:
        print(f"üíæ Storing new best partial result: {confidence}/10 (previous: {current_best}/10)")
        best_partial = {
            "confidence": confidence,
            "reasoning": reasoning,
            "results": results,
            "attempt": attempt,
            "query": state["current_query"],
            "timestamp": datetime.now().isoformat()
        }
        
        # Update state with new best partial
        state = {
            **state,
            "best_partial_result": best_partial,
            "best_partial_confidence": confidence,
            "has_usable_partial": True
        }
    
    # Track attempt confidence
    attempt_confidences = state.get("attempt_confidences", [])
    attempt_confidences.append(confidence)
    
    # Get dynamic threshold based on intent
    confidence_threshold = state.get("confidence_threshold_override", 7.0)
    
    evaluation_entry = f"Model evaluation: {confidence}/10 - {reasoning[:50]}..."
    
    # DOSAGE-SPECIFIC FALLBACK (unchanged)
    if (state["query_intent"] == "dosage" and 
        confidence < confidence_threshold and 
        attempt >= MAX_REASONING_ATTEMPTS):
        
        print(f"üíä DOSAGE FALLBACK: Providing packaging instructions")
        return generate_dosage_fallback(state, evaluation_entry)
    
    # STANDARD CONFIDENCE EVALUATION
    if confidence >= confidence_threshold:
        status = "EXCELLENT" if confidence >= 9.0 else "GOOD"
        print(f"‚úÖ {status} content quality ({confidence}/10) - generating answer")
        return {
            **state, 
            "model_confidence": confidence,
            "should_continue": False,
            "attempt_confidences": attempt_confidences,
            "evaluation_log": [evaluation_entry]
        }
    
    # CHECK FOR MAX ATTEMPTS REACHED
    elif attempt >= MAX_REASONING_ATTEMPTS:
        print(f"‚ö†Ô∏è Max attempts reached ({attempt}) - checking augmentation eligibility...")
        return check_augmentation_eligibility(state, confidence, evaluation_entry, attempt_confidences)
    
    # CONTINUE REASONING  
    else:
        print(f"ü§î Content quality insufficient ({confidence}/10) - continuing reasoning")
        evaluation_entry += f" | Insufficient quality, continuing"
        return {
            **state, 
            "model_confidence": confidence,
            "should_continue": True,
            "attempt_confidences": attempt_confidences,
            "evaluation_log": [evaluation_entry]
        }

def check_augmentation_eligibility(state: EnhancedEvaluationRAGStateV2, 
                                 current_confidence: float, 
                                 evaluation_entry: str,
                                 attempt_confidences: List[float]) -> EnhancedEvaluationRAGStateV2:
    """üÜï Decide: GPT Augmentation vs Standard Escalation"""
    
    has_partial = state.get("has_usable_partial", False)
    best_confidence = state.get("best_partial_confidence", 0.0)
    query_intent = state.get("query_intent", "general")
    
    # Protected query types (no augmentation)
    protected_intents = ["business", "dosage", "production"]
    
    print(f"üîç Augmentation check:")
    print(f"   - Has partial: {has_partial} (best: {best_confidence}/10)")
    print(f"   - Query intent: {query_intent}")
    print(f"   - Protected: {query_intent in protected_intents}")
    
    # AUGMENTATION CONDITIONS
    if (has_partial and 
        best_confidence >= 5.0 and 
        query_intent not in protected_intents):
        
        print(f"üß† TRIGGERING GPT AUGMENTATION (partial: {best_confidence}/10)")
        evaluation_entry += f" | Max attempts reached - triggering GPT augmentation with partial {best_confidence}/10"
        
        return {
            **state,
            "should_continue": False,
            "escalate": False,
            "use_augmentation": True,  # üÜï Trigger augmentation
            "model_confidence": current_confidence,
            "attempt_confidences": attempt_confidences,
            "augmentation_reasoning": f"Using partial result from attempt {state['best_partial_result']['attempt']} with confidence {best_confidence}/10",
            "evaluation_log": [evaluation_entry]
        }
    
    # STANDARD ESCALATION
    else:
        reason = "no usable partial" if not has_partial else f"protected intent: {query_intent}"
        print(f"‚ö†Ô∏è Standard escalation ({reason})")
        evaluation_entry += f" | Max attempts reached - escalating ({reason})"
        
        return {
            **state, 
            "model_confidence": current_confidence,
            "should_continue": False, 
            "escalate": True,
            "attempt_confidences": attempt_confidences,
            "evaluation_log": [evaluation_entry]
        }

def gpt_augmentation_mode(state: EnhancedEvaluationRAGStateV2) -> EnhancedEvaluationRAGStateV2:
    """üÜï NEW: GPT Knowledge Augmentation with safety controls"""
    print(f"üß† GPT AUGMENTATION MODE ACTIVATED")
    
    partial = state["best_partial_result"]
    best_confidence = state["best_partial_confidence"]
    
    print(f"üìö Using partial result from attempt {partial['attempt']} (confidence: {best_confidence}/10)")
    
    # Build context from best partial result
    partial_content = ""
    for i, result in enumerate(partial["results"][:3]):
        partial_content += f"--- ≈πR√ìD≈ÅO {i+1} ---\n"
        partial_content += f"Tytu≈Ç: {result['title']}\n"
        partial_content += f"Typ: {result.get('content_type', 'unknown')}\n"
        partial_content += f"Tre≈õƒá: {result['full_content'][:400]}...\n\n"
    
    # Controlled augmentation prompt
    augmentation_prompt = f"""
    {ENHANCED_AQUAFOREST_EXPERT_PROMPT}
    
    === TRYB AUGMENTACJI WIEDZY ===
    
    Masz czƒô≈õciowƒÖ wiedzƒô z bazy Aquaforest (confidence: {best_confidence}/10), 
    ale jest niewystarczajƒÖca do pe≈Çnej odpowiedzi na pytanie u≈ºytkownika.
    
    CZƒò≈öCIOWA WIEDZA Z BAZY AQUAFOREST:
    {partial_content}
    
    PYTANIE U≈ªYTKOWNIKA: "{state['original_query']}"
    
    ZADANIE - CONTROLLED AUGMENTATION:
    1. üéØ Wykorzystaj znalezione tre≈õci jako FOUNDATION - to jest najwa≈ºniejsze
    2. üß† Dope≈Çnij brakujƒÖcƒÖ wiedzƒô domenowƒÖ z zakresu akwarystyki/Aquaforest
    3. üõ°Ô∏è Pozosta≈Ñ w kontek≈õcie znalezionych tre≈õci - NIE odchod≈∫ od tematu
    4. ‚ùå NIE dodawaj informacji sprzecznych z tre≈õciami z bazy
    5. üìù Jasno zaznacz co pochodzi z bazy, a co jest uzupe≈Çnieniem
    6. ‚ö†Ô∏è Je≈õli nie mo≈ºesz bezpiecznie uzupe≈Çniƒá - powiedz to wprost
    7. üîó Zawsze dodaj kontakt do ekspert√≥w dla weryfikacji
    
    STRUKTURA ODPOWIEDZI:
    **Na podstawie dostƒôpnych informacji Aquaforest:**
    [konkretne tre≈õci z bazy RAG]
    
    **Dodatkowo w kontek≈õcie akwarystyki:**
    [bezpieczne uzupe≈Çnienie domenowe, je≈õli mo≈ºliwe]
    
    **‚ö†Ô∏è Dla potwierdzenia szczeg√≥≈Ç√≥w skontaktuj siƒô z ekspertami:**
    üìû Telefon: (+48) 14 691 79 79 (pon-pt, 8:00-16:00)
    üåê Kontakt: https://aquaforest.eu/pl/kontakt/
    
    ODPOWIED≈π EKSPERTA AQUAFOREST:
    """
    
    try:
        print(f"üéØ Generating augmented response...")
        response = components.llm.invoke([SystemMessage(content=augmentation_prompt)])
        augmented_answer = response.content.strip()
        
        print(f"üìù Generated augmented response ({len(augmented_answer)} chars)")
        
        # üÜï SECOND EVALUATION - czy augmentacja jest bezpieczna i skuteczna?
        second_confidence, second_reasoning = evaluate_augmented_response(
            augmented_answer, 
            state["original_query"], 
            partial_content
        )
        
        print(f"üîç Second evaluation: {second_confidence}/10")
        print(f"üí≠ Second reasoning: {second_reasoning[:100]}...")
        
        # Safety checks
        safety_passed = passes_safety_checks(augmented_answer, partial_content)
        print(f"üõ°Ô∏è Safety checks: {'PASSED' if safety_passed else 'FAILED'}")
        
        # Final decision
        if second_confidence >= 7.0 and safety_passed:
            print(f"‚úÖ AUGMENTATION SUCCESS! Using augmented response")
            return {
                **state,
                "final_answer": augmented_answer,
                "model_confidence": second_confidence,
                "augmentation_used": True,
                "augmentation_confidence": second_confidence,
                "should_continue": False,
                "escalate": False,
                "evaluation_log": [f"GPT augmentation successful: {second_confidence}/10 | {second_reasoning[:50]}..."]
            }
        else:
            reason = f"Low confidence: {second_confidence}/10" if second_confidence < 7.0 else "Safety check failed"
            print(f"‚ùå AUGMENTATION FAILED: {reason}")
            return {
                **state,
                "escalate": True,
                "should_continue": False,
                "augmentation_used": False,
                "augmentation_reasoning": f"Augmentation failed: {reason}",
                "evaluation_log": [f"GPT augmentation failed: {reason} | {second_reasoning[:50]}..."]
            }
            
    except Exception as e:
        print(f"‚ùå AUGMENTATION ERROR: {e}")
        return {
            **state,
            "escalate": True,
            "should_continue": False,
            "augmentation_used": False,
            "augmentation_reasoning": f"Augmentation error: {str(e)}",
            "evaluation_log": [f"GPT augmentation error: {str(e)}"]
        }

def evaluate_augmented_response(augmented_response: str, 
                              original_query: str, 
                              partial_content: str) -> tuple[float, str]:
    """üîç Second evaluation for augmented responses"""
    
    eval_prompt = f"""
    Oce≈Ñ jako≈õƒá tej augmentowanej odpowiedzi na skali 1-10:
    
    PYTANIE U≈ªYTKOWNIKA: "{original_query}"
    
    AUGMENTOWANA ODPOWIED≈π:
    {augmented_response}
    
    ORYGINALNA WIEDZA Z BAZY:
    {partial_content[:500]}...
    
    === KRYTERIA OCENY ===
    
    üéØ **RELEVANCE** (czy odpowiada na pytanie):
    - 1-3: Nie odpowiada na pytanie u≈ºytkownika
    - 4-6: Czƒô≈õciowo odpowiada, ale niepe≈Çne  
    - 7-8: Dobrze odpowiada na pytanie
    - 9-10: Perfekcyjnie odpowiada na pytanie
    
    üìä **CONSISTENCY** (sp√≥jno≈õƒá z bazƒÖ wiedzy):
    - 1-3: Sprzeczne z bazowƒÖ wiedzƒÖ
    - 4-6: Czƒô≈õciowo sp√≥jne, niekt√≥re niezgodno≈õci
    - 7-8: W pe≈Çni sp√≥jne z bazƒÖ
    - 9-10: Doskonale wykorzystuje bazƒô jako foundation
    
    üõ°Ô∏è **SAFETY** (bezpiecze≈Ñstwo, brak halucynacji):
    - 1-3: Wyra≈∫ne halucynacje, wymy≈õlone fakty
    - 4-6: Og√≥lnikowe, ale bezpieczne
    - 7-8: Faktyczne, bez halucynacji  
    - 9-10: Bardzo precyzyjne i bezpieczne
    
    üîß **ACTIONABILITY** (praktyczno≈õƒá):
    - 1-3: Brak konkretnych wskaz√≥wek
    - 4-6: Og√≥lne porady
    - 7-8: Konkretne, actionable steps
    - 9-10: Bardzo precyzyjne instrukcje
    
    ‚ö†Ô∏è **PENALTY FACTORS** (obni≈º ocenƒô za):
    - Wymy≈õlone konkretne liczby/dawki/produkty
    - Informacje sprzeczne z bazƒÖ wiedzy
    - Brak kontaktu do ekspert√≥w (powinien byƒá!)
    - Zbyt d≈Çugie lub zbyt kr√≥tkie odpowiedzi
    
    RESPOND IN FORMAT:
    CONFIDENCE: [number 1-10]
    REASONING: [brief explanation why this rating]
    """
    
    try:
        response = components.llm.invoke([SystemMessage(content=eval_prompt)])
        evaluation_text = response.content
        
        # Extract confidence score
        confidence_match = re.search(r'CONFIDENCE:\s*([1-9]|10)', evaluation_text)
        reasoning_match = re.search(r'REASONING:\s*(.+)', evaluation_text, re.DOTALL)
        
        confidence = float(confidence_match.group(1)) if confidence_match else 3.0
        reasoning = reasoning_match.group(1).strip() if reasoning_match else "No reasoning provided"
        
        return confidence, reasoning
        
    except Exception as e:
        print(f"‚ùå Second evaluation error: {e}")
        return 3.0, f"Evaluation failed: {e}"

def passes_safety_checks(augmented_response: str, original_content: str) -> bool:
    """üõ°Ô∏è Safety checks for augmented responses"""
    
    # Check 1: Reasonable length (not too short/long)
    if len(augmented_response) < 150 or len(augmented_response) > 2500:
        print(f"‚ö†Ô∏è Safety fail: Length {len(augmented_response)} chars (should be 150-2500)")
        return False
    
    # Check 2: Contains reference to contacting experts (mandatory for safety)
    contact_keywords = ["kontakt", "ekspert", "691 79 79", "aquaforest.eu", "telefon"]
    has_contact_ref = any(keyword in augmented_response.lower() for keyword in contact_keywords)
    if not has_contact_ref:
        print(f"‚ö†Ô∏è Safety fail: No expert contact reference")
        return False
    
    # Check 3: Contains foundation reference (should mention base knowledge)
    foundation_keywords = ["na podstawie", "dostƒôpnych informacji", "z bazy", "aquaforest"]
    has_foundation_ref = any(keyword in augmented_response.lower() for keyword in foundation_keywords)
    if not has_foundation_ref:
        print(f"‚ö†Ô∏è Safety fail: No foundation reference")
        return False
    
    # Check 4: Basic structure check (should have multiple sections)
    if augmented_response.count('\n') < 3:
        print(f"‚ö†Ô∏è Safety fail: Poor structure (too few sections)")
        return False
    
    print(f"‚úÖ Safety checks passed")
    return True

def generate_dosage_fallback(state: EnhancedEvaluationRAGStateV2, evaluation_entry: str) -> EnhancedEvaluationRAGStateV2:
    """üíä Generate dosage fallback response"""
    
    dosage_fallback = f"""Nie znalaz≈Çem szczeg√≥≈Çowych informacji o dawkowaniu w bazie wiedzy Aquaforest.

üì¶ **Instrukcje dawkowania znajdujƒÖ siƒô na opakowaniu produktu**
- Zawsze sprawd≈∫ etykietƒô przed u≈ºyciem
- Rozpocznij od najmniejszej zalecanej dawki  
- Obserwuj reakcjƒô akwarium i dostosuj dawkƒô

üí° **Og√≥lne zasady Aquaforest:**
- Dawki na etykiecie sƒÖ bezpieczne dla standardowych akwari√≥w
- W przypadku wƒÖtpliwo≈õci skonsultuj z do≈õwiadczonym akwarystƒÖ
- Regularnie testuj parametry wody po dodaniu preparatu

üìû **Pomoc techniczna**: (+48) 14 691 79 79 (pon-pt, 8:00-16:00)

üåê **Wiƒôcej informacji**: https://aquaforest.eu/pl/kontakt/"""
    
    return {
        **state, 
        "final_answer": dosage_fallback,
        "should_continue": False,
        "model_confidence": 7.0,  # Good fallback response
        "evaluation_log": [evaluation_entry + " | Dosage fallback used"]
    }

def execute_search_attempt(state: EnhancedEvaluationRAGStateV2) -> EnhancedEvaluationRAGStateV2:
    """
    üöÄ ENHANCED SEARCH ATTEMPT with Dynamic Query Optimization
    
    Replaces static pattern matching with intelligent LLM-based semantic understanding
    """
    attempt = state["attempt_count"] + 1
    original_query = state["original_query"]
    query_intent = state.get("query_intent", "general")
    
    print(f"üîç Enhanced Search Attempt {attempt}/{MAX_REASONING_ATTEMPTS}")
    
    # üÜï BUILD CONTEXT FROM PREVIOUS ATTEMPTS for intelligent optimization
    previous_attempts = []
    if attempt > 1:
        attempt_history = state.get("attempt_history", [])
        evaluation_log = state.get("evaluation_log", [])
        attempt_confidences = state.get("attempt_confidences", [])
        
        for i, history_entry in enumerate(attempt_history):
            if i < len(attempt_confidences):
                previous_attempts.append({
                    'optimal_query': history_entry.get('optimized_query', ''),
                    'confidence': attempt_confidences[i],
                    'reasoning': evaluation_log[i] if i < len(evaluation_log) else 'No reasoning',
                    'result_count': history_entry.get('results_count', 0)
                })
    
    # üß† DYNAMIC QUERY OPTIMIZATION USING LLM (replaces static patterns)
    optimized_query = components.optimize_query_for_attempt(
        original_query=original_query,
        attempt=attempt,
        previous_evaluations=state.get("evaluation_log", []),
        query_intent=query_intent
    )
    
    print(f"üéØ Intelligent Query Optimization:")
    print(f"   üìù Original: '{original_query}'")
    print(f"   üéØ Intent: {query_intent}")
    print(f"   üß† Optimized: '{optimized_query}'")
    
    # üîç ADVANCED SEARCH STRATEGY based on attempt
    search_strategies = {
        1: {"top_k": 8, "use_multi_query": False},      # Focused search
        2: {"top_k": 12, "use_multi_query": True},      # Expanded with variants
        3: {"top_k": 16, "use_multi_query": True}       # Broadest search
    }
    
    strategy = search_strategies.get(attempt, search_strategies[3])
    print(f"üì° Search Strategy: top_k={strategy['top_k']}, multi_query={strategy['use_multi_query']}")
    
    # üöÄ EXECUTE ENHANCED SEARCH
    search_results = components.search_knowledge_enhanced(
        query=optimized_query,
        top_k=strategy["top_k"],
        use_multi_query=strategy["use_multi_query"]
    )
    
    print(f"üìö Found {len(search_results)} results")
    
    # üìä ENHANCED ATTEMPT TRACKING
    attempt_info = {
        "attempt": attempt,
        "original_query": original_query,
        "optimized_query": optimized_query,
        "query_intent": query_intent,
        "search_strategy": strategy,
        "results_count": len(search_results),
        "optimization_type": "dynamic_llm_based",  # üÜï Track optimization type
        "timestamp": datetime.now().isoformat()
    }
    
    # Update state with enhanced tracking
    attempt_history = state.get("attempt_history", [])
    attempt_history.append(attempt_info)
    
    all_results = state.get("all_results", [])
    all_results.append(search_results)
    
    return {
        **state,
        "attempt_count": attempt,
        "current_query": optimized_query,
        "search_results": search_results,
        "attempt_history": attempt_history,
        "all_results": all_results,
        "evaluation_log": [f"Enhanced Attempt {attempt}: LLM optimization '{optimized_query}' ‚Üí {len(search_results)} results (strategy: {strategy})"]
    }

def generate_evaluation_answer(state: EnhancedEvaluationRAGStateV2) -> EnhancedEvaluationRAGStateV2:
    """Node 4: Generate final answer based on search results"""
    
    # Check if we should escalate instead
    if state.get("escalate", False):
        escalation_response = f"""Przepraszam, ale nie znalaz≈Çem wystarczajƒÖcych informacji w bazie wiedzy Aquaforest aby odpowiedzieƒá na Twoje pytanie: "{state['original_query']}"

üìû **Skontaktuj siƒô bezpo≈õrednio z naszymi ekspertami:**
- **Telefon**: (+48) 14 691 79 79 (pon-pt, 8:00-16:00)
- **Website**: https://aquaforest.eu/pl/kontakt/

üß† **Nasi specjali≈õci pomogƒÖ Ci z:**
- Szczeg√≥≈Çowym doradztwem technicznym
- InterpretacjƒÖ wynik√≥w test√≥w  
- OptymalizacjƒÖ parametr√≥w akwarium
- RozwiƒÖzywaniem problem√≥w hodowlanych

**Przygotuj do rozmowy:**
- Model i pojemno≈õƒá akwarium
- Aktualne parametry wody  
- Stosowane produkty Aquaforest
- Opis problemu lub pytania

Czekamy na Tw√≥j telefon! üåä"""
        
        return {
            **state,
            "final_answer": escalation_response,
            "should_continue": False
        }
    
    # Generate answer from good quality results
    results = state["search_results"]
    query = state["original_query"]
    confidence = state["model_confidence"]
    
    print(f"üìù Generating final answer (confidence: {confidence}/10)")
    
    # Prepare context from search results
    context = ""
    for i, result in enumerate(results[:4]):  # Top 4 results
        context += f"\n--- ≈πR√ìD≈ÅO {i+1} ---\n"
        context += f"Tytu≈Ç: {result['title']}\n"
        context += f"Typ: {result.get('content_type', 'unknown')}\n"
        context += f"Tre≈õƒá: {result['full_content']}\n"
        if result.get('url'):
            context += f"URL: {result['url']}\n"
    
    # Generate comprehensive answer
    answer_prompt = f"""
    {ENHANCED_AQUAFOREST_EXPERT_PROMPT}
    
    === GENEROWANIE ODPOWIEDZI EKSPERTA ===
    
    PYTANIE U≈ªYTKOWNIKA: "{query}"
    
    ≈πR√ìD≈ÅA Z BAZY WIEDZY AQUAFOREST:
    {context}
    
    ZADANIE:
    Napisz kompletnƒÖ, profesjonalnƒÖ odpowied≈∫ jako ekspert Aquaforest wykorzystujƒÖc dostƒôpne ≈∫r√≥d≈Ça.
    
    WYMAGANIA ODPOWIEDZI:
    ‚úÖ Bezpo≈õrednio odpowiedz na pytanie u≈ºytkownika
    ‚úÖ Wykorzystaj konkretne informacje ze ≈∫r√≥de≈Ç
    ‚úÖ Dodaj praktyczne wskaz√≥wki krok po kroku
    ‚úÖ Uwzglƒôdnij specyfikƒô produkt√≥w Aquaforest
    ‚úÖ Zachowaj profesjonalny, pomocny ton
    ‚úÖ Dodaj kontakt do ekspert√≥w na ko≈Ñcu
    
    STRUKTURA:
    1. **Bezpo≈õrednia odpowied≈∫** na pytanie
    2. **Szczeg√≥≈Çy techniczne** z bazy wiedzy
    3. **Praktyczne wskaz√≥wki** krok po kroku
    4. **Kontakt ekspercki** dla dalszej pomocy
    
    ‚ùå NIE DODAWAJ informacji sprzecznych ze ≈∫r√≥d≈Çami
    ‚ùå NIE WYMY≈öLAJ konkretnych liczb/dawek bez potwierdzenia
    ‚ùå NIE U≈ªYWAJ og√≥lnikowych porad
    
    ODPOWIED≈π EKSPERTA AQUAFOREST:
    """
    
    try:
        response = components.llm.invoke([SystemMessage(content=answer_prompt)])
        final_answer = response.content.strip()
        
        # Add expert contact if not present
        if "691 79 79" not in final_answer and "aquaforest.eu" not in final_answer:
            final_answer += f"""

üìû **Dodatkowa pomoc ekspert√≥w Aquaforest:**
- Telefon: (+48) 14 691 79 79 (pon-pt, 8:00-16:00)
- Website: https://aquaforest.eu/pl/kontakt/"""
        
        print(f"‚úÖ Generated answer ({len(final_answer)} characters)")
        
        return {
            **state,
            "final_answer": final_answer,
            "should_continue": False
        }
        
    except Exception as e:
        print(f"‚ùå Answer generation error: {e}")
        return {
            **state,
            "final_answer": f"B≈ÇƒÖd generowania odpowiedzi: {e}. Skontaktuj siƒô z ekspertami: (+48) 14 691 79 79",
            "should_continue": False,
            "escalate": True
        }